{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H(z) Reconstrution via Gaussian Process (GP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from gaussian_process import GPReconstructionH\n",
    "from plots_rec import HReconstructionPlot\n",
    "from equations import FiducialModel\n",
    "from obs_data import H_data\n",
    "\n",
    "# Load your data\n",
    "data_Hz = H_data()\n",
    "\n",
    "z_values, H_obs, errors = data_Hz.H_z_data()\n",
    "\n",
    "# Choose the GP parameters\n",
    "gp_h = GPReconstructionH(z_values, H_obs, errors)\n",
    "gp_h.optimize(num_restarts=10, verbose=False)\n",
    "mean, var, mean_deriv, var_deriv = gp_h.predict()\n",
    "z_val = gp_h.z_pred()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Combine os dados em um array de duas colunas\n",
    "data_to_save = np.column_stack((z_val, mean))\n",
    "\n",
    "# Salve no arquivo .txt\n",
    "np.savetxt('data/H_rec_gp_data.txt', data_to_save, fmt='%.6f', header='z_val  mean', comments='')\n",
    "\n",
    "\n",
    "fiducial_model = FiducialModel()\n",
    "\n",
    "# Plot the figure\n",
    "plotter = HReconstructionPlot(gp_h, fiducial_model)\n",
    "plotter.plot('Figuras/H_reconstructed.png')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H(z) Reconstrution via Artificial Neural Network (ANN): ReFANN code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import refann as rf\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Starting the ANN\n",
    "start_time = time.time()\n",
    "\n",
    "Hz = np.loadtxt('data/Hz35data.txt', skiprows=1)\n",
    "\n",
    "rec = rf.ANN(Hz,mid_node=4096,hidden_layer=1,hp_model='rec_2')\n",
    "rec.iteration = 30000\n",
    "rec.train()\n",
    "func = rec.predict(xpoint=np.linspace(0, 2, 201))\n",
    "#func = rec.predict(xspace=(0, 2, 201)) #or use this\n",
    "rec.save_func(path='data', obsName='Hz35') #save the reconstructed function\n",
    "\n",
    "# rec.plot_loss()\n",
    "rec.plot_func()\n",
    "print (\"Time elapsed: %.3f mins\" %((time.time()-start_time)/60))\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian analysis and MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from likelihood import JointPriors\n",
    "\n",
    "# Defining the priors and the type of distribuition\n",
    "param_configs_w_frb = {\n",
    "    # 'Omega_bh2': ((0.01,0.05), 'uniform'), \n",
    "    'Omega_bh2': ((0.02235, 0.00049), 'gaussian'),\n",
    "    'DM_host_0': ((55, 225), 'uniform')\n",
    "}\n",
    "\n",
    "param_configs_w_sne = {\n",
    "    'H0': ((20, 100), 'uniform'),\n",
    "    'Omega_m': ((0.1, 0.9), 'uniform')\n",
    "}\n",
    "\n",
    "P_frb = JointPriors(param_configs_w_frb)\n",
    "P_sne = JointPriors(param_configs_w_sne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from likelihood import JointLikelihoodFunction\n",
    "from equations import DM_EXT_model_Rec, Modulus_sne\n",
    "\n",
    "model = DM_EXT_model_Rec()\n",
    "mu_wCDM = Modulus_sne()\n",
    "\n",
    "# Creating an instance of JointLikelihoodFunction\n",
    "LF_gp_frb = JointLikelihoodFunction(\n",
    "    { 'FRB': lambda z, Omega_bh2, DM_host_0: model.DM_ext_th(\n",
    "        z=z,\n",
    "        f_IGM=0.83,\n",
    "        model_type='constant',\n",
    "        Omega_bh2=Omega_bh2,     \n",
    "        DM_host_0=DM_host_0,\n",
    "        rec_type='GP'\n",
    "    ) \n",
    "    }\n",
    ")\n",
    "\n",
    "LF_ann_frb = JointLikelihoodFunction(\n",
    "    { 'FRB': lambda z, Omega_bh2, DM_host_0: model.DM_ext_th(\n",
    "        z=z,\n",
    "        f_IGM=0.83,\n",
    "        model_type='constant',\n",
    "        Omega_bh2=Omega_bh2,     \n",
    "        DM_host_0=DM_host_0,\n",
    "        rec_type='ANN'\n",
    "    ) \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis for 66 FRBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obs_data import FRB_data, SNe_data\n",
    "import ultranest\n",
    "\n",
    "# Instantiate the FRB_data class for 66 FRBs\n",
    "frb_data = FRB_data(n_frb=66)\n",
    "\n",
    "# Call the select_data method to get the observed data\n",
    "z_frb, DM_ext, sigma_ext = frb_data.select_data()\n",
    "\n",
    "\"\"\"sne_data_union = SNe_data(sample_sne='Union3')\n",
    "\n",
    "z_sne_union, mu_sne_union, cov_matrix_inv_union = sne_data_union.load_data()\n",
    "\n",
    "sne_data_pantheon = SNe_data(sample_sne='Pantheon+SH0ES')\n",
    "\n",
    "z_sne, z_alt, mu_sne, cov_matrix_inv = sne_data_pantheon.load_data()\"\"\"\n",
    "\n",
    "# Configuring the ultranest samplers\n",
    "sampler_gp_frb = ultranest.ReactiveNestedSampler(\n",
    "    P_frb.param_names,\n",
    "    lambda params: LF_gp_frb.log_likelihood(\n",
    "        dict(zip(P_frb.param_names, params)),\n",
    "        {\n",
    "            'FRB': (z_frb, DM_ext, sigma_ext)\n",
    "        }\n",
    "    ),\n",
    "    P_frb.prior_transform\n",
    ")\n",
    "\n",
    "sampler_ann_frb = ultranest.ReactiveNestedSampler(\n",
    "    P_frb.param_names,\n",
    "    lambda params: LF_ann_frb.log_likelihood(\n",
    "        dict(zip(P_frb.param_names, params)),\n",
    "        {\n",
    "            'FRB': (z_frb, DM_ext, sigma_ext)\n",
    "        }\n",
    "    ),\n",
    "    P_frb.prior_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_frb = sampler_gp_frb.run(min_num_live_points=400)\n",
    "sampler_gp_frb.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_frb = sampler_ann_frb.run(min_num_live_points=400)\n",
    "sampler_ann_frb.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getdist import plots, MCSamples\n",
    "import numpy as np\n",
    "\n",
    "# Extraindo amostras dos resultados para frb\n",
    "samples_gp_frb = gp_frb['samples']\n",
    "samples_ann_frb = ann_frb['samples']\n",
    "\n",
    "labels1 = ['\\\\Omega_{b}h^2', 'DM_{host,0}']\n",
    "names1 = P_frb.param_names\n",
    "\n",
    "# Calculando o par칙metro derivado\n",
    "derived_param_gp = 100 * np.sqrt(samples_gp_frb[:, 0] / 0.0493)\n",
    "derived_param_ann = 100 * np.sqrt(samples_ann_frb[:, 0] / 0.0493)\n",
    "\n",
    "# Adicionando o par칙metro derivado nas amostras\n",
    "samples_with_derived_gp = np.hstack([samples_gp_frb, derived_param_gp[:, None]])\n",
    "samples_with_derived_ann = np.hstack([samples_ann_frb, derived_param_ann[:, None]])\n",
    "\n",
    "names_extended = names1 + ['H0']\n",
    "labels_extended = ['\\\\Omega_{b}h^2', 'DM_{host,0}', 'H_0']\n",
    "\n",
    "# Criando MCSamples com o par칙metro derivado\n",
    "mcsamples_gp_frb = MCSamples(samples=samples_with_derived_gp, \n",
    "                           names=names_extended, \n",
    "                           labels=labels_extended)\n",
    "\n",
    "mcsamples_ann_frb = MCSamples(samples=samples_with_derived_ann, \n",
    "                           names=names_extended, \n",
    "                           labels=labels_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os Triangle plots\n",
    "g = plots.get_subplot_plotter()\n",
    "mcsamples_ann_frb.updateSettings({'smooth_scale_2D': 0.9, 'smooth_scale_1D': 0.9})\n",
    "mcsamples_gp_frb.updateSettings({'smooth_scale_2D': 0.9, 'smooth_scale_1D': 0.9})\n",
    "g.settings.num_plot_contours = 2\n",
    "g.triangle_plot([mcsamples_gp_frb, mcsamples_ann_frb], names1, filled=True, contour_colors=['blue', 'red'], \n",
    "                legend_labels=['GaPP', 'ReFANN'])\n",
    "g.export('Figuras/rec_frb.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dicion치rio de amostras e nomes de arquivos\n",
    "amostras = {\n",
    "    \"frb_gapp\": samples_gp_frb,\n",
    "    \"frb_refann\": samples_ann_frb\n",
    "}\n",
    "\n",
    "# Salva cada conjunto de amostras em arquivos CSV\n",
    "for nome, dados in amostras.items():\n",
    "    df = pd.DataFrame(dados)\n",
    "    df.to_csv(f\"Samplers/{nome}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import pandas as pd\n",
    "df1_frb = pd.read_csv(\"Samplers/samples1_frb.csv\")\n",
    "df1_sne = pd.read_csv(\"Samplers/samples1_sne.csv\")\n",
    "df1_sne_frb = pd.read_csv(\"Samplers/samples1_sne_frb.csv\")\n",
    "df2_frb = pd.read_csv(\"Samplers/samples2_frb.csv\")\n",
    "df2_sne = pd.read_csv(\"Samplers/samples2_sne.csv\")\n",
    "df2_sne_frb = pd.read_csv(\"Samplers/samples2_sne_frb.csv\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"samples = {\n",
    "    \"Sample_frb\": {\n",
    "        \"results\": {\n",
    "            'wCDM': {'logz': wCDM_frb['logz'], 'num_params': 5},\n",
    "            'CPL': {'logz': CPL_frb['logz'], 'num_params': 6},\n",
    "        }\n",
    "    },\n",
    "    \"Sample_sne\": {\n",
    "        \"results\": {\n",
    "            'wCDM': {'logz': wCDM_sne['logz'], 'num_params': 5},\n",
    "            'CPL': {'logz': CPL_sne['logz'], 'num_params': 6},\n",
    "        }\n",
    "    },\n",
    "    \"Sample_sne_frb\": {\n",
    "        \"results\": {\n",
    "            'wCDM': {'logz': wCDM_sne_frb['logz'], 'num_params': 5},\n",
    "            'CPL': {'logz': CPL_sne_frb['logz'], 'num_params': 6},\n",
    "        }\n",
    "    }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from bayesian_analysis import ModelComparison\n",
    "\n",
    "comparison = ModelComparison(samples)\n",
    "comparison.run_comparisons(save_to_file='comparisons_output_frb+SNe.txt')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesian_analysis import SaveResults\n",
    "\n",
    "# Initialize the class with the desired output file\n",
    "results_saver = SaveResults(\"Results_mcmc/results_frb_rec_Hz.txt\")\n",
    "\n",
    "# Optional: Clear the file if you want to start fresh\n",
    "results_saver.reset_file()\n",
    "\n",
    "results_saver.save_to_txt(mcsamples_gp_frb, 'GaPP')\n",
    "results_saver.save_to_txt(mcsamples_ann_frb, 'Refann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesian_analysis import CompareMCMCResults\n",
    "\n",
    "comparator = CompareMCMCResults('Results_mcmc/mcmc_comparison_results.txt')\n",
    "\n",
    "comparator.reset_file()\n",
    "\n",
    "# Faz a compara칞칚o entre os dois modelos\n",
    "comparator.compare_errors(mcsamples_gp_frb, mcsamples_ann_frb, \"GaPP\", \"Refann\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from ultranest.plot import PredictionBand\n",
    "from equations import DM_EXT_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('$z$')\n",
    "plt.ylabel('$DM_{ext}(z)$')\n",
    "plt.errorbar(x=z_values_16, y=dm_ext_obs_16, fmt='o', alpha=0.6, color='red', label='16 FRBs', ms=2)\n",
    "\n",
    "z_test = np.linspace(0, 1, 100)\n",
    "\n",
    "band = PredictionBand(z_test)\n",
    "model_fit = DM_EXT_model()\n",
    "# go through the solutions\n",
    "for H_0, A, beta, omega_0, omega_a  in sampler_p2_16.results['samples']:\n",
    "    # compute for each time the y value\n",
    "    band.add(model_fit.DM_ext_th(z=z_test,\n",
    "        f_IGM=0.83,\n",
    "        model_type='constant',\n",
    "        Omega_b=None,  \n",
    "        Omega_m=None,     \n",
    "        H_today=H_0,\n",
    "        A=A,\n",
    "        beta=beta,\n",
    "        omega_0=omega_0,  \n",
    "        omega_a=omega_a,\n",
    "        cosmo_type='non_standard',\n",
    "        param_type='CPL'))\n",
    "\n",
    "band.line(color='k', linestyle='-', label='CPL parameterization', linewidth=1.5)\n",
    "# add 1 sigma quantile\n",
    "band.shade(color='green', alpha=0.3)\n",
    "# add wider quantile (0.01 .. 0.99)\n",
    "band.shade(q=0.49, color='green', alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('Figuras/DM_ext_bestfit_16.png', format='png', dpi=600)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from ultranest.plot import PredictionBand\n",
    "from equations import DM_EXT_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('$z$')\n",
    "plt.ylabel('$DM_{ext}(z)$')\n",
    "plt.errorbar(x=z_values_63, y=dm_ext_obs_63, fmt='o', alpha=0.6, color='red', label='63 FRBs', ms=2)\n",
    "\n",
    "z_test = np.linspace(0, 1.1, 100)\n",
    "\n",
    "band = PredictionBand(z_test)\n",
    "model_fit = DM_EXT_model()\n",
    "# go through the solutions\n",
    "for H_0, A, beta, omega_0  in sampler_constant_63.results['samples']:\n",
    "    # compute for each time the y value\n",
    "    band.add(model_fit.DM_ext_th(z=z_test,\n",
    "        f_IGM=0.83,\n",
    "        model_type='constant',\n",
    "        Omega_b=None,  \n",
    "        Omega_m=None,     \n",
    "        H_today=H_0,\n",
    "        A=A,\n",
    "        beta=beta,\n",
    "        omega_0=omega_0,\n",
    "        cosmo_type='non_standard',\n",
    "        param_type='constant')\n",
    "    )\n",
    "\n",
    "band.line(color='k', linestyle='-', label='Constant parameterization', linewidth=1.5)\n",
    "# add 1 sigma quantile\n",
    "band.shade(color='green', alpha=0.3)\n",
    "# add wider quantile (0.01 .. 0.99)\n",
    "band.shade(q=0.49, color='green', alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('Figuras/DM_ext_bestfit_63.png', format='png', dpi=600)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_frblip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
