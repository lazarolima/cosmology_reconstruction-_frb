{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H(z) Reconstrution via Gaussian Process (GP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from gaussian_process import GPReconstructionH\\nfrom plots_rec import HReconstructionPlot\\nfrom equations import FiducialModel\\nfrom obs_data import H_data\\n\\n# Load your data\\ndata_Hz = H_data()\\n\\nz_values, H_obs, errors = data_Hz.H_z_data()\\n\\n# Choose the GP parameters\\ngp_h = GPReconstructionH(z_values, H_obs, errors)\\ngp_h.optimize(num_restarts=10, verbose=False)\\nmean, var, mean_deriv, var_deriv = gp_h.predict()\\nz_val = gp_h.z_pred()\\n\\nimport numpy as np\\n\\n# Combine os dados em um array de duas colunas\\ndata_to_save = np.column_stack((z_val, mean))\\n\\n# Salve no arquivo .txt\\nnp.savetxt('data/H_rec_gp_data.txt', data_to_save, fmt='%.6f', header='z_val  mean', comments='')\\n\\n\\nfiducial_model = FiducialModel()\\n\\n# Plot the figure\\nplotter = HReconstructionPlot(gp_h, fiducial_model)\\nplotter.plot('Figuras/H_reconstructed.png')\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from gaussian_process import GPReconstructionH\n",
    "from plots_rec import HReconstructionPlot\n",
    "from equations import FiducialModel\n",
    "from obs_data import H_data\n",
    "\n",
    "# Load your data\n",
    "data_Hz = H_data()\n",
    "\n",
    "z_values, H_obs, errors = data_Hz.H_z_data()\n",
    "\n",
    "# Choose the GP parameters\n",
    "gp_h = GPReconstructionH(z_values, H_obs, errors)\n",
    "gp_h.optimize(num_restarts=10, verbose=False)\n",
    "mean, var, mean_deriv, var_deriv = gp_h.predict()\n",
    "z_val = gp_h.z_pred()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Combine os dados em um array de duas colunas\n",
    "data_to_save = np.column_stack((z_val, mean))\n",
    "\n",
    "# Salve no arquivo .txt\n",
    "np.savetxt('data/H_rec_gp_data.txt', data_to_save, fmt='%.6f', header='z_val  mean', comments='')\n",
    "\n",
    "\n",
    "fiducial_model = FiducialModel()\n",
    "\n",
    "# Plot the figure\n",
    "plotter = HReconstructionPlot(gp_h, fiducial_model)\n",
    "plotter.plot('Figuras/H_reconstructed.png')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H(z) Reconstrution via Artificial Neural Network (ANN): ReFANN code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import refann as rf\\nimport time\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Starting the ANN\\nstart_time = time.time()\\n\\nHz = np.loadtxt(\\'data/Hz35data.txt\\', skiprows=1)\\n\\nrec = rf.ANN(Hz,mid_node=4096,hidden_layer=1,hp_model=\\'rec_2\\')\\nrec.iteration = 30000\\nrec.train()\\nfunc = rec.predict(xpoint=np.linspace(0, 2, 201))\\n#func = rec.predict(xspace=(0, 2, 201)) #or use this\\nrec.save_func(path=\\'data\\', obsName=\\'Hz35\\') #save the reconstructed function\\n\\n# rec.plot_loss()\\nrec.plot_func()\\nprint (\"Time elapsed: %.3f mins\" %((time.time()-start_time)/60))\\nplt.show()'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import refann as rf\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Starting the ANN\n",
    "start_time = time.time()\n",
    "\n",
    "Hz = np.loadtxt('data/Hz35data.txt', skiprows=1)\n",
    "\n",
    "rec = rf.ANN(Hz,mid_node=4096,hidden_layer=1,hp_model='rec_2')\n",
    "rec.iteration = 30000\n",
    "rec.train()\n",
    "func = rec.predict(xpoint=np.linspace(0, 2, 201))\n",
    "#func = rec.predict(xspace=(0, 2, 201)) #or use this\n",
    "rec.save_func(path='data', obsName='Hz35') #save the reconstructed function\n",
    "\n",
    "# rec.plot_loss()\n",
    "rec.plot_func()\n",
    "print (\"Time elapsed: %.3f mins\" %((time.time()-start_time)/60))\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian analysis and MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from likelihood import JointPriors\n",
    "\n",
    "# Defining the priors and the type of distribuition\n",
    "param_configs_w_frb = {\n",
    "    # 'Omega_bh2': ((0.02, 0.03), 'uniform'), \n",
    "    'Omega_bh2': ((0.02235, 0.00049), 'gaussian'),\n",
    "    'A': ((55, 225), 'uniform'),\n",
    "    'beta': ((0, 4), 'uniform')\n",
    "}\n",
    "\n",
    "P_frb = JointPriors(param_configs_w_frb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from likelihood import JointLikelihoodFunction\n",
    "from equations import DM_EXT_model_Rec, Modulus_sne\n",
    "from obs_data import FRB_data\n",
    "\n",
    "model = DM_EXT_model_Rec()\n",
    "mu_wCDM = Modulus_sne()\n",
    "\n",
    "# Instantiate the FRB_data class for 66 FRBs\n",
    "frb_data = FRB_data(n_frb=66)\n",
    "\n",
    "# Call the select_data method to get the observed data\n",
    "z_frb, DM_ext, sigma_ext = frb_data.select_data()\n",
    "\n",
    "# Creating an instance of JointLikelihoodFunction\n",
    "LF_gp_frb = JointLikelihoodFunction(\n",
    "    { 'FRB_pdf': lambda z, Omega_bh2, A, beta: model.DM_ext_pdf(\n",
    "        z=z,\n",
    "        f_IGM=0.83,\n",
    "        model_type='constant',\n",
    "        Omega_bh2=Omega_bh2,     \n",
    "        A=A,\n",
    "        beta=beta,\n",
    "        rec_type='GP',\n",
    "        sigma_igm=sigma_ext,\n",
    "        dm_ext_obs=DM_ext\n",
    "    ) \n",
    "    }\n",
    ")\n",
    "\n",
    "LF_ann_frb = JointLikelihoodFunction(\n",
    "    { 'FRB_pdf': lambda z, Omega_bh2, A, beta: model.DM_ext_pdf(\n",
    "        z=z,\n",
    "        f_IGM=0.83,\n",
    "        model_type='constant',\n",
    "        Omega_bh2=Omega_bh2,     \n",
    "        A=A,\n",
    "        beta=beta,\n",
    "        rec_type='ANN',\n",
    "        sigma_igm=sigma_ext,\n",
    "        dm_ext_obs=DM_ext\n",
    "    ) \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis for 66 FRBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obs_data import FRB_data, SNe_data\n",
    "import ultranest\n",
    "\n",
    "# Instantiate the FRB_data class for 66 FRBs\n",
    "frb_data = FRB_data(n_frb=66)\n",
    "\n",
    "# Call the select_data method to get the observed data\n",
    "z_frb, DM_ext, sigma_ext = frb_data.select_data()\n",
    "\n",
    "# sne_data_union = SNe_data(sample_sne='Union3')\n",
    "\n",
    "# z_sne_union, mu_sne_union, cov_matrix_inv_union = sne_data_union.load_data()\n",
    "\n",
    "# sne_data_pantheon = SNe_data(sample_sne='Pantheon+SH0ES')\n",
    "\n",
    "# z_sne, z_alt, mu_sne, cov_matrix_inv = sne_data_pantheon.load_data()\n",
    "\n",
    "# Configuring the ultranest samplers\n",
    "sampler_gp_frb = ultranest.ReactiveNestedSampler(\n",
    "    P_frb.param_names,\n",
    "    lambda params: LF_gp_frb.log_likelihood(\n",
    "        dict(zip(P_frb.param_names, params)),\n",
    "        {\n",
    "            'FRB_pdf': (z_frb, DM_ext, sigma_ext)\n",
    "            #'FRB_pdf': (z_frb)\n",
    "        }\n",
    "    ),\n",
    "    P_frb.prior_transform\n",
    ")\n",
    "\n",
    "sampler_ann_frb = ultranest.ReactiveNestedSampler(\n",
    "    P_frb.param_names,\n",
    "    lambda params: LF_ann_frb.log_likelihood(\n",
    "        dict(zip(P_frb.param_names, params)),\n",
    "        {\n",
    "            'FRB_pdf': (z_frb, DM_ext, sigma_ext)\n",
    "            #'FRB_pdf': (z_frb)\n",
    "        }\n",
    "    ),\n",
    "    P_frb.prior_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultranest] Sampling 400 live points from prior ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078c47cc23ee49a89b8bf15210472d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), GridspecLayout(children=(HTML(value=\"<div style='background-color:#6E6BF4;'>&nb…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultranest] Explored until L=-1e+03  .20 [-966.5023..-966.5022]*| it/evals=6982/17242 eff=41.4499% N=399   \n",
      "[ultranest] Likelihood function evaluations: 17242\n",
      "[ultranest]   logZ = -978.8 +- 0.08785\n",
      "[ultranest] Effective samples strategy satisfied (ESS = 3638.7, need >400)\n",
      "[ultranest] Posterior uncertainty strategy is satisfied (KL: 0.45+-0.06 nat, need <0.50 nat)\n",
      "[ultranest] Evidency uncertainty strategy is satisfied (dlogz=0.09, need <0.5)\n",
      "[ultranest]   logZ error budget: single: 0.13 bs:0.09 tail:0.01 total:0.09 required:<0.50\n",
      "[ultranest] done iterating.\n",
      "\n",
      "logZ = -978.775 +- 0.148\n",
      "  single instance: logZ = -978.775 +- 0.132\n",
      "  bootstrapped   : logZ = -978.777 +- 0.148\n",
      "  tail           : logZ = +- 0.010\n",
      "insert order U test : converged: True correlation: inf iterations\n",
      "\n",
      "    Omega_bh2           : 0.02002│▁▁▁▁▁▂▂▃▃▄▅▆▇▆▇▇▇▇▆▇▆▅▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁ │0.02317    0.02132 +- 0.00047\n",
      "    A                   : 79.8  │ ▁ ▁▁▁▁▁▁▁▂▃▃▃▅▆▅▇▇▇▇▇▆▆▅▄▄▃▂▂▁▁▁▁▁▁▁▁ │128.9     105.0 +- 6.5\n",
      "    beta                : 2.33  │ ▁ ▁▁▁▁▁▁▁▁▁▂▂▃▄▅▆▇▇▇▇▇▆▅▅▃▂▁▁▁▁▁▁   ▁ │3.71      3.05 +- 0.14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gp_frb = sampler_gp_frb.run(min_num_live_points=400)\n",
    "sampler_gp_frb.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_frb = sampler_ann_frb.run(min_num_live_points=400)\n",
    "sampler_ann_frb.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed no burn in\n"
     ]
    }
   ],
   "source": [
    "from getdist import plots, MCSamples\n",
    "import numpy as np\n",
    "\n",
    "# Extraindo amostras dos resultados para frb\n",
    "samples_gp_frb = gp_frb['samples']\n",
    "#samples_ann_frb = ann_frb['samples']\n",
    "\n",
    "labels1 = ['\\\\Omega_{b}h^2', 'A', '\\\\beta']\n",
    "names1 = P_frb.param_names\n",
    "\n",
    "# Calculando o parâmetro derivado\n",
    "derived_param_gp = 100 * np.sqrt(samples_gp_frb[:, 0] / 0.0493)\n",
    "#derived_param_ann = 100 * np.sqrt(samples_ann_frb[:, 0] / 0.0493)\n",
    "\n",
    "# Adicionando o parâmetro derivado nas amostras\n",
    "samples_with_derived_gp = np.hstack([samples_gp_frb, derived_param_gp[:, None]])\n",
    "#samples_with_derived_ann = np.hstack([samples_ann_frb, derived_param_ann[:, None]])\n",
    "\n",
    "names_extended = names1 + ['H0']\n",
    "labels_extended = ['\\\\Omega_{b}h^2', 'A', '\\\\beta', 'H_0']\n",
    "\n",
    "# Criando MCSamples com o parâmetro derivado\n",
    "mcsamples_gp_frb = MCSamples(samples=samples_with_derived_gp, \n",
    "                           names=names_extended, \n",
    "                           labels=labels_extended)\n",
    "\n",
    "# mcsamples_ann_frb = MCSamples(samples=samples_with_derived_ann, \n",
    "#                            names=names_extended, \n",
    "#                            labels=labels_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcsamples_gp_frb.getMargeStats().saveAsText('Results_mcmc/marginalized_params_gp.txt')\n",
    "mcsamples_ann_frb.getMargeStats().saveAsText('Results_mcmc/marginalized_params_ann.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os Triangle plots\n",
    "g = plots.get_subplot_plotter()\n",
    "#mcsamples_ann_frb.updateSettings({'smooth_scale_2D': 0.9, 'smooth_scale_1D': 0.9})\n",
    "mcsamples_gp_frb.updateSettings({'smooth_scale_2D': 0.9, 'smooth_scale_1D': 0.9})\n",
    "g.settings.num_plot_contours = 2\n",
    "g.triangle_plot([mcsamples_gp_frb], names1, filled=True, contour_colors=['green', 'red'], \n",
    "                legend_labels=['GaPP', 'Refann'])\n",
    "g.export('Figuras/rec_frb_dm_host(z).png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dicionário de amostras e nomes de arquivos\n",
    "amostras = {\n",
    "    \"frb_gapp_dm_host\": samples_gp_frb,\n",
    "    \"frb_refann_dm_host\": samples_ann_frb\n",
    "}\n",
    "\n",
    "# Salva cada conjunto de amostras em arquivos CSV\n",
    "for nome, dados in amostras.items():\n",
    "    df = pd.DataFrame(dados)\n",
    "    df.to_csv(f\"Samplers/{nome}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import pandas as pd\n",
    "df1_frb = pd.read_csv(\"Samplers/samples1_frb.csv\")\n",
    "df1_sne = pd.read_csv(\"Samplers/samples1_sne.csv\")\n",
    "df1_sne_frb = pd.read_csv(\"Samplers/samples1_sne_frb.csv\")\n",
    "df2_frb = pd.read_csv(\"Samplers/samples2_frb.csv\")\n",
    "df2_sne = pd.read_csv(\"Samplers/samples2_sne.csv\")\n",
    "df2_sne_frb = pd.read_csv(\"Samplers/samples2_sne_frb.csv\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"samples = {\n",
    "    \"Sample_frb\": {\n",
    "        \"results\": {\n",
    "            'wCDM': {'logz': wCDM_frb['logz'], 'num_params': 5},\n",
    "            'CPL': {'logz': CPL_frb['logz'], 'num_params': 6},\n",
    "        }\n",
    "    },\n",
    "    \"Sample_sne\": {\n",
    "        \"results\": {\n",
    "            'wCDM': {'logz': wCDM_sne['logz'], 'num_params': 5},\n",
    "            'CPL': {'logz': CPL_sne['logz'], 'num_params': 6},\n",
    "        }\n",
    "    },\n",
    "    \"Sample_sne_frb\": {\n",
    "        \"results\": {\n",
    "            'wCDM': {'logz': wCDM_sne_frb['logz'], 'num_params': 5},\n",
    "            'CPL': {'logz': CPL_sne_frb['logz'], 'num_params': 6},\n",
    "        }\n",
    "    }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from bayesian_analysis import ModelComparison\n",
    "\n",
    "comparison = ModelComparison(samples)\n",
    "comparison.run_comparisons(save_to_file='comparisons_output_frb+SNe.txt')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesian_analysis import SaveResults\n",
    "\n",
    "# Initialize the class with the desired output file\n",
    "results_saver = SaveResults(\"Results_mcmc/results_frb_rec_Hz_dm_host(z).txt\")\n",
    "\n",
    "# Optional: Clear the file if you want to start fresh\n",
    "results_saver.reset_file()\n",
    "\n",
    "results_saver.save_to_txt(mcsamples_gp_frb, 'GaPP')\n",
    "#results_saver.save_to_txt(mcsamples_ann_frb, 'Refann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesian_analysis import CompareMCMCResults\n",
    "\n",
    "comparator = CompareMCMCResults('Results_mcmc/mcmc_comparison_results_dm_host(z).txt')\n",
    "\n",
    "comparator.reset_file()\n",
    "\n",
    "# Faz a comparação entre os dois modelos\n",
    "comparator.compare_errors(mcsamples_gp_frb, mcsamples_ann_frb, \"GaPP\", \"Refann\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from ultranest.plot import PredictionBand\n",
    "from equations import DM_EXT_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('$z$')\n",
    "plt.ylabel('$DM_{ext}(z)$')\n",
    "plt.errorbar(x=z_values_16, y=dm_ext_obs_16, fmt='o', alpha=0.6, color='red', label='16 FRBs', ms=2)\n",
    "\n",
    "z_test = np.linspace(0, 1, 100)\n",
    "\n",
    "band = PredictionBand(z_test)\n",
    "model_fit = DM_EXT_model()\n",
    "# go through the solutions\n",
    "for H_0, A, beta, omega_0, omega_a  in sampler_p2_16.results['samples']:\n",
    "    # compute for each time the y value\n",
    "    band.add(model_fit.DM_ext_th(z=z_test,\n",
    "        f_IGM=0.83,\n",
    "        model_type='constant',\n",
    "        Omega_b=None,  \n",
    "        Omega_m=None,     \n",
    "        H_today=H_0,\n",
    "        A=A,\n",
    "        beta=beta,\n",
    "        omega_0=omega_0,  \n",
    "        omega_a=omega_a,\n",
    "        cosmo_type='non_standard',\n",
    "        param_type='CPL'))\n",
    "\n",
    "band.line(color='k', linestyle='-', label='CPL parameterization', linewidth=1.5)\n",
    "# add 1 sigma quantile\n",
    "band.shade(color='green', alpha=0.3)\n",
    "# add wider quantile (0.01 .. 0.99)\n",
    "band.shade(q=0.49, color='green', alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('Figuras/DM_ext_bestfit_16.png', format='png', dpi=600)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from ultranest.plot import PredictionBand\n",
    "from equations import DM_EXT_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('$z$')\n",
    "plt.ylabel('$DM_{ext}(z)$')\n",
    "plt.errorbar(x=z_values_63, y=dm_ext_obs_63, fmt='o', alpha=0.6, color='red', label='63 FRBs', ms=2)\n",
    "\n",
    "z_test = np.linspace(0, 1.1, 100)\n",
    "\n",
    "band = PredictionBand(z_test)\n",
    "model_fit = DM_EXT_model()\n",
    "# go through the solutions\n",
    "for H_0, A, beta, omega_0  in sampler_constant_63.results['samples']:\n",
    "    # compute for each time the y value\n",
    "    band.add(model_fit.DM_ext_th(z=z_test,\n",
    "        f_IGM=0.83,\n",
    "        model_type='constant',\n",
    "        Omega_b=None,  \n",
    "        Omega_m=None,     \n",
    "        H_today=H_0,\n",
    "        A=A,\n",
    "        beta=beta,\n",
    "        omega_0=omega_0,\n",
    "        cosmo_type='non_standard',\n",
    "        param_type='constant')\n",
    "    )\n",
    "\n",
    "band.line(color='k', linestyle='-', label='Constant parameterization', linewidth=1.5)\n",
    "# add 1 sigma quantile\n",
    "band.shade(color='green', alpha=0.3)\n",
    "# add wider quantile (0.01 .. 0.99)\n",
    "band.shade(q=0.49, color='green', alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('Figuras/DM_ext_bestfit_63.png', format='png', dpi=600)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_frblip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
